# Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs

This repository accompanies the paper:

> **Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs**  
> *Tristan Williams, Franziska Weeber, Sebastian Padó, and Alan Akbik*

## Overview

Large language models (LLMs) are increasingly used as proxies for human opinions, values, and beliefs. A growing body of work studies *demographic alignment* or *steerability* by comparing model-generated survey responses to human data. Existing evaluations, however, focus almost exclusively on matching **marginal response distributions**, treating survey items as independent.

This repository implements a framework for evaluating ***representativeness beyond marginals***, motivated by cultural values research. In addition to marginal distributions, we assess whether aligned models reproduce the **multivariate correlation structure** observed in real populations.

We illustrate the framework by using data from the ***World Values Survey (WVS)*** and demonstrate that models which appear well-aligned under marginal-based evaluations can nonetheless fail to capture the latent structure of human values. 


## Key Contributions

### Evaluation Framework

The framework evaluates representativeness from two perspectives:

1. Marginal response distributions: How well do simulated responses approximate the ground truth response distribution? 
2. Multivariate correlation structures: Do the simulated responses reproduce the interactions between questions and topics that underpin the WVS and related social scientific research?

### Model comparison

We then apply our framework to compare two techniques for model steering using World Values Survey data:
1. Demographic fine-tuning (specifically OpinionGPT)
2. Persona prompting (using Phi 3 Mini)

Additionally, we consider an unsteered version of Phi 3 as a baseline. We find that OpinionGPT displays 
improved marginal distribution similarity and response diversity compared to the persona prompting approach and the unsteered baseline.
However, neither model steering approach accurately reproduces the correlation structures observed in the true human survey responses.

## Data

- Human responses are drawn from the **World Values Survey** Wave 7.
- Model responses are generated by prompting or fine-tuned models to answer the same survey items under controlled conditions.

## Repository Structure

```text
├── data_files
│   └── variables           # WVS survey items
├── scripts                 # Helper scripts for running experiments and data processing
├── src
│   ├── analysis            # Representativeness metrics and evaluation logic
│   ├── data                # Data loading and preprocessing utilities
│   ├── demographics        # Demographic grouping and conditioning logic
│   ├── prompting
│   └── simulation          # Model response generation and sampling
└── tests                   # unit and data integrity tests
```

## Setup
1. Install dependencies in your virtual environment with `pip install -r requirements.txt`
2. Use the `.env.example` to create an `.env` file with your HF token
3. Download the file `WVS Cross-National Wave 7 csv v6 0.zip` from the WVS website [here](https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp) and, after unzipping, place the csv file in `data_files/WV7`

## Usage
1. Simulate responses with all models (we used an NVIDIA A100 80GB PCIe GPU)
```
python3 scripts/run_all_models.py -experiment_name <name>
```
2. Convert the json results to csv
```
python3 scripts/results_to_csv.py -experiment_name <name>
```
3. Clean simulated outputs
```
python3 scripts/clean_results.py -experiment_name <name>
```
4. Run the analysis of marginal response distributions
```
python3 scripts/generate_marginal_analysis.py -experiment_name <name>
```
5. Run the analysis of the correlation structures
```
python3 scripts/generate_correlation_analysis.py -experiment_name <name>
```
6. Generate visualisations
```
python3 scripts/generate_visualisations.py -experiment_name <name>
```

## Citation

```bibtex
@misc{williams2026representativeness,
  title         = {Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs},
  author        = {Williams, Tristan and Weeber, Franzika and Padó, Sebastian and Akbik, Alan},
  eprint        = {2601.15755},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL},
  url           = {https://arxiv.org/abs/2601.15755}, 
  year          = {2026}
}
```
